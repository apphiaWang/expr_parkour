{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk6_qGt6xU5E"
      },
      "source": [
        "# 0. Google Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXYLwuIaxUtC",
        "outputId": "435968de-e7ac-4cc6-d8c8-585bc7fdf0fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCsppv_bxLQb"
      },
      "outputs": [],
      "source": [
        "os.chdir('./drive/MyDrive/cmpt419 affective computing project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y92R6_fd9fNK",
        "outputId": "eff43090-424e-4bc4-c8b5-f74dfc899f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_pos_embd\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_pos_embd) (1.25.2)\n",
            "Building wheels for collected packages: keras_pos_embd\n",
            "  Building wheel for keras_pos_embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_pos_embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=f7d07e8c36048719514702c5e8aaa3f14724199275547f330a7055cc8456c261\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "Successfully built keras_pos_embd\n",
            "Installing collected packages: keras_pos_embd\n",
            "Successfully installed keras_pos_embd-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_pos_embd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7aEOO_1_7_-",
        "outputId": "25c0824a-065b-4e6e-8230-3559ad5eb506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_layer_normalization\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_layer_normalization) (1.25.2)\n",
            "Building wheels for collected packages: keras_layer_normalization\n",
            "  Building wheel for keras_layer_normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_layer_normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=511125a9452eb3f3ae40e40e8d24c44fdefb7e314453bedd81000c7f03287251\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "Successfully built keras_layer_normalization\n",
            "Installing collected packages: keras_layer_normalization\n",
            "Successfully installed keras_layer_normalization-0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_layer_normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWFwPq8g_-gl",
        "outputId": "03cfb578-40e3-4a0d-e334-a4212326ea79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_multi_head\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras_multi_head)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention==0.51.0->keras_multi_head) (1.25.2)\n",
            "Building wheels for collected packages: keras_multi_head, keras-self-attention\n",
            "  Building wheel for keras_multi_head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_multi_head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14976 sha256=b9bf3ac761064fa4d84880ce54e509905d2ba9db05dc2f60b55abc43598d76e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18894 sha256=5ed3561d0cd02bbf77713ab9b049eafeb1e63662bdcd8f87f5b3bc45913110bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "Successfully built keras_multi_head keras-self-attention\n",
            "Installing collected packages: keras-self-attention, keras_multi_head\n",
            "Successfully installed keras-self-attention-0.51.0 keras_multi_head-0.29.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_multi_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtt0aPBLAA5z",
        "outputId": "84ff63ae-9681-458b-ce0e-f996690f3911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_position_wise_feed_forward\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_position_wise_feed_forward) (1.25.2)\n",
            "Building wheels for collected packages: keras_position_wise_feed_forward\n",
            "  Building wheel for keras_position_wise_feed_forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_position_wise_feed_forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4969 sha256=830a687f76d29568b696ddbad5c2798fb5b907b4b0f2b020ce9ade95e31e686c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "Successfully built keras_position_wise_feed_forward\n",
            "Installing collected packages: keras_position_wise_feed_forward\n",
            "Successfully installed keras_position_wise_feed_forward-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_position_wise_feed_forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GNwCzxLAD3S",
        "outputId": "7535b9cf-4239-457e-ea64-ace4c9e67375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_embed_sim\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_embed_sim) (1.25.2)\n",
            "Building wheels for collected packages: keras_embed_sim\n",
            "  Building wheel for keras_embed_sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_embed_sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=ec4d4b721bde595402acb764df057b4e3f375d5bd9f74e666edbc5c906fc1d86\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "Successfully built keras_embed_sim\n",
            "Installing collected packages: keras_embed_sim\n",
            "Successfully installed keras_embed_sim-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_embed_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4x94uHL-Ymh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Activation, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Reshape, Permute, Multiply, Add, Concatenate\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "# other keras related library\n",
        "from keras_pos_embd import PositionEmbedding, TrigPosEmbedding\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from keras_multi_head import MultiHeadAttention\n",
        "from keras_position_wise_feed_forward import FeedForward\n",
        "from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
        "\n",
        "import math\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZMlofTv9xsH"
      },
      "source": [
        "# 1. Transformer Encoders\n",
        "+ The transformer encoders takes in the discriminative AU embeddings as inputs. The component of the AU correlation contains multi-head attentions layer and a feed forward layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hef3o1Kw9xVN"
      },
      "outputs": [],
      "source": [
        "def gelu(x):\n",
        "    \"\"\"An approximation of gelu.\n",
        "    See: https://arxiv.org/pdf/1606.08415.pdf\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1.0 + tf.math.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * x * x * x)))\n",
        "\n",
        "def get_custom_objects():\n",
        "    return {\n",
        "        'gelu': gelu,\n",
        "        'LayerNormalization': LayerNormalization,\n",
        "        'MultiHeadAttention': MultiHeadAttention,\n",
        "        'FeedForward': FeedForward,\n",
        "        'TrigPosEmbedding': TrigPosEmbedding,\n",
        "        'EmbeddingRet': EmbeddingRet,\n",
        "        'EmbeddingSim': EmbeddingSim,\n",
        "    }\n",
        "\n",
        "\n",
        "def _wrap_layer(name,\n",
        "        input_layer,\n",
        "        build_func,\n",
        "        dropout_rate=0.0,\n",
        "        trainable=True):\n",
        "    \"\"\"Wrap layers with residual, normalization and dropout.\n",
        "    :param name: Prefix of names for internal layers.\n",
        "    :param input_layer: Input layer.\n",
        "    :param build_func: A callable that takes the input tensor and generates the output tensor.\n",
        "    :param dropout_rate: Dropout rate.\n",
        "    :param trainable: Whether the layers are trainable.\n",
        "    :return: Output layer.\n",
        "    \"\"\"\n",
        "    build_output = build_func(input_layer)\n",
        "    if dropout_rate > 0.0:\n",
        "        dropout_layer = Dropout(\n",
        "            rate=dropout_rate,\n",
        "            name='%s-Dropout' % name,\n",
        "        )(build_output)\n",
        "    else:\n",
        "        dropout_layer = build_output\n",
        "    if isinstance(input_layer, list):\n",
        "        input_layer = input_layer[0]\n",
        "    add_layer = Add(name='%s-Add' % name)([input_layer, dropout_layer])\n",
        "    normal_layer = LayerNormalization(\n",
        "        trainable=trainable,\n",
        "        name='%s-Norm' % name,\n",
        "    )(add_layer)\n",
        "    return normal_layer\n",
        "\n",
        "def attention_builder(name,\n",
        "                      head_num,\n",
        "                      activation,\n",
        "                      history_only,\n",
        "                      trainable=True):\n",
        "    \"\"\"Get multi-head self-attention builder.\n",
        "    :param name: Prefix of names for internal layers.\n",
        "    :param head_num: Number of heads in multi-head self-attention.\n",
        "    :param activation: Activation for multi-head self-attention.\n",
        "    :param history_only: Only use history data.\n",
        "    :param trainable: Whether the layer is trainable.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    def _attention_builder(x):\n",
        "        return MultiHeadAttention(\n",
        "            head_num=head_num,\n",
        "            activation=activation,\n",
        "            history_only=history_only,\n",
        "            trainable=trainable,\n",
        "            name=name,\n",
        "        )(x)\n",
        "    return _attention_builder\n",
        "\n",
        "\n",
        "def feed_forward_builder(name,\n",
        "                         hidden_dim,\n",
        "                         activation,\n",
        "                         trainable=True):\n",
        "    \"\"\"Get position-wise feed-forward layer builder.\n",
        "    :param name: Prefix of names for internal layers.\n",
        "    :param hidden_dim: Hidden dimension of feed forward layer.\n",
        "    :param activation: Activation for feed-forward layer.\n",
        "    :param trainable: Whether the layer is trainable.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    def _feed_forward_builder(x):\n",
        "        return FeedForward(\n",
        "            units=hidden_dim,\n",
        "            activation=activation,\n",
        "            trainable=trainable,\n",
        "            name=name,\n",
        "        )(x)\n",
        "    return _feed_forward_builder\n",
        "\n",
        "\n",
        "def get_encoder_component(name,\n",
        "              input_layer,\n",
        "              head_num,\n",
        "              hidden_dim,\n",
        "              attention_activation=None,\n",
        "              feed_forward_activation=gelu,\n",
        "              dropout_rate=0.0,\n",
        "              trainable=True,):\n",
        "    \"\"\"Multi-head self-attention and feed-forward layer.\n",
        "    :param name: Prefix of names for internal layers.\n",
        "    :param input_layer: Input layer.\n",
        "    :param head_num: Number of heads in multi-head self-attention.\n",
        "    :param hidden_dim: Hidden dimension of feed forward layer.\n",
        "    :param attention_activation: Activation for multi-head self-attention.\n",
        "    :param feed_forward_activation: Activation for feed-forward layer.\n",
        "    :param dropout_rate: Dropout rate.\n",
        "    :param trainable: Whether the layers are trainable.\n",
        "    :return: Output layer.\n",
        "    \"\"\"\n",
        "    attention_name = '%s-MultiHeadSelfAttention' % name\n",
        "    feed_forward_name = '%s-FeedForward' % name\n",
        "    attention_layer = _wrap_layer(\n",
        "        name=attention_name,\n",
        "        input_layer=input_layer,\n",
        "        build_func=attention_builder(\n",
        "            name=attention_name,\n",
        "            head_num=head_num,\n",
        "            activation=attention_activation,\n",
        "            history_only=False,\n",
        "            trainable=trainable,\n",
        "        ),\n",
        "        dropout_rate=dropout_rate,\n",
        "        trainable=trainable,\n",
        "    )\n",
        "    feed_forward_layer = _wrap_layer(\n",
        "        name=feed_forward_name,\n",
        "        input_layer=attention_layer,\n",
        "        build_func=feed_forward_builder(\n",
        "            name=feed_forward_name,\n",
        "            hidden_dim=hidden_dim,\n",
        "            activation=feed_forward_activation,\n",
        "            trainable=trainable,\n",
        "        ),\n",
        "        dropout_rate=dropout_rate,\n",
        "        trainable=trainable,\n",
        "    )\n",
        "\n",
        "    return feed_forward_layer\n",
        "\n",
        "# we didn't use the decoder\n",
        "def get_decoder_component(name,\n",
        "              input_layer,\n",
        "              encoded_layer,\n",
        "              head_num,\n",
        "              hidden_dim,\n",
        "              attention_activation=None,\n",
        "              feed_forward_activation=gelu,\n",
        "              dropout_rate=0.0,\n",
        "              trainable=True):\n",
        "    \"\"\"Multi-head self-attention, multi-head query attention and feed-forward layer.\n",
        "    :param name: Prefix of names for internal layers.\n",
        "    :param input_layer: Input layer.\n",
        "    :param encoded_layer: Encoded layer from encoder.\n",
        "    :param head_num: Number of heads in multi-head self-attention.\n",
        "    :param hidden_dim: Hidden dimension of feed forward layer.\n",
        "    :param attention_activation: Activation for multi-head self-attention.\n",
        "    :param feed_forward_activation: Activation for feed-forward layer.\n",
        "    :param dropout_rate: Dropout rate.\n",
        "    :param trainable: Whether the layers are trainable.\n",
        "    :return: Output layer.\n",
        "    \"\"\"\n",
        "    self_attention_name = '%s-MultiHeadSelfAttention' % name\n",
        "    query_attention_name = '%s-MultiHeadQueryAttention' % name\n",
        "    feed_forward_name = '%s-FeedForward' % name\n",
        "    self_attention_layer = _wrap_layer(\n",
        "        name=self_attention_name,\n",
        "        input_layer=input_layer,\n",
        "        build_func=attention_builder(\n",
        "            name=self_attention_name,\n",
        "            head_num=head_num,\n",
        "            activation=attention_activation,\n",
        "            history_only=True,\n",
        "            trainable=trainable,\n",
        "        ),\n",
        "        dropout_rate=dropout_rate,\n",
        "        trainable=trainable,\n",
        "    )\n",
        "    query_attention_layer = _wrap_layer(\n",
        "        name=query_attention_name,\n",
        "        input_layer=[self_attention_layer, encoded_layer, encoded_layer],\n",
        "        build_func=attention_builder(\n",
        "            name=query_attention_name,\n",
        "            head_num=head_num,\n",
        "            activation=attention_activation,\n",
        "            history_only=False,\n",
        "            trainable=trainable,\n",
        "        ),\n",
        "        dropout_rate=dropout_rate,\n",
        "        trainable=trainable,\n",
        "    )\n",
        "    feed_forward_layer = _wrap_layer(\n",
        "        name=feed_forward_name,\n",
        "        input_layer=query_attention_layer,\n",
        "        build_func=feed_forward_builder(\n",
        "            name=feed_forward_name,\n",
        "            hidden_dim=hidden_dim,\n",
        "            activation=feed_forward_activation,\n",
        "            trainable=trainable,\n",
        "        ),\n",
        "        dropout_rate=dropout_rate,\n",
        "        trainable=trainable,\n",
        "    )\n",
        "    return feed_forward_layer\n",
        "\n",
        "def get_encoders(name,encoder_num,\n",
        "          input_layer,\n",
        "          head_num,\n",
        "          hidden_dim,\n",
        "          attention_activation=None,\n",
        "          feed_forward_activation=gelu,\n",
        "          dropout_rate=0.0,\n",
        "          trainable=True):\n",
        "    \"\"\"Get encoders.\n",
        "    :param encoder_num: Number of encoder components.\n",
        "    :param input_layer: Input layer.\n",
        "    :param head_num: Number of heads in multi-head self-attention.\n",
        "    :param hidden_dim: Hidden dimension of feed forward layer.\n",
        "    :param attention_activation: Activation for multi-head self-attention.\n",
        "    :param feed_forward_activation: Activation for feed-forward layer.\n",
        "    :param dropout_rate: Dropout rate.\n",
        "    :param trainable: Whether the layers are trainable.\n",
        "    :return: Output layer.\n",
        "    \"\"\"\n",
        "    last_layer = input_layer\n",
        "    for i in range(encoder_num):\n",
        "        last_layer = get_encoder_component(\n",
        "            name='%sEncoder-%d' % (name,i + 1),\n",
        "            input_layer=last_layer,\n",
        "            head_num=head_num,\n",
        "            hidden_dim=hidden_dim,\n",
        "            attention_activation=attention_activation,\n",
        "            feed_forward_activation=feed_forward_activation,\n",
        "            dropout_rate=dropout_rate,\n",
        "            trainable=trainable,\n",
        "        )\n",
        "    return last_layer\n",
        "\n",
        "\n",
        "def get_decoders(name,decoder_num,\n",
        "                 input_layer,\n",
        "                 encoded_layer,\n",
        "                 head_num,\n",
        "                 hidden_dim,\n",
        "                 attention_activation=None,\n",
        "                 feed_forward_activation=gelu,\n",
        "                 dropout_rate=0.0,\n",
        "                 trainable=True):\n",
        "    \"\"\"Get decoders.\n",
        "    :param decoder_num: Number of decoder components.\n",
        "    :param input_layer: Input layer.\n",
        "    :param encoded_layer: Encoded layer from encoder.\n",
        "    :param head_num: Number of heads in multi-head self-attention.\n",
        "    :param hidden_dim: Hidden dimension of feed forward layer.\n",
        "    :param attention_activation: Activation for multi-head self-attention.\n",
        "    :param feed_forward_activation: Activation for feed-forward layer.\n",
        "    :param dropout_rate: Dropout rate.\n",
        "    :param trainable: Whether the layers are trainable.\n",
        "    :return: Output layer.\n",
        "    \"\"\"\n",
        "    last_layer = input_layer\n",
        "    for i in range(decoder_num):\n",
        "        last_layer = get_decoder_component(\n",
        "            name='%sDecoder-%d' % (name,i + 1),\n",
        "            input_layer=last_layer,\n",
        "            encoded_layer=encoded_layer,\n",
        "            head_num=head_num,\n",
        "            hidden_dim=hidden_dim,\n",
        "            attention_activation=attention_activation,\n",
        "            feed_forward_activation=feed_forward_activation,\n",
        "            dropout_rate=dropout_rate,\n",
        "            trainable=trainable,\n",
        "        )\n",
        "    return last_layer\n",
        "\n",
        "\n",
        "# def get_model(token_num,\n",
        "#               embed_dim,\n",
        "#               encoder_num,\n",
        "#               decoder_num,\n",
        "#               head_num,\n",
        "#               hidden_dim,\n",
        "#               attention_activation=None,\n",
        "#               feed_forward_activation=gelu,\n",
        "#               dropout_rate=0.0,\n",
        "#               use_same_embed=True,\n",
        "#               embed_weights=None,\n",
        "#               embed_trainable=None,\n",
        "#               trainable=True):\n",
        "#     \"\"\"Get full model without compilation.\n",
        "#     :param token_num: Number of distinct tokens.\n",
        "#     :param embed_dim: Dimension of token embedding.\n",
        "#     :param encoder_num: Number of encoder components.\n",
        "#     :param decoder_num: Number of decoder components.\n",
        "#     :param head_num: Number of heads in multi-head self-attention.\n",
        "#     :param hidden_dim: Hidden dimension of feed forward layer.\n",
        "#     :param attention_activation: Activation for multi-head self-attention.\n",
        "#     :param feed_forward_activation: Activation for feed-forward layer.\n",
        "#     :param dropout_rate: Dropout rate.\n",
        "#     :param use_same_embed: Whether to use the same token embedding layer. `token_num`, `embed_weights` and\n",
        "#                            `embed_trainable` should be lists of two elements if it is False.\n",
        "#     :param embed_weights: Initial weights of token embedding.\n",
        "#     :param embed_trainable: Whether the token embedding is trainable. It will automatically set to False if the given\n",
        "#                             value is None when embedding weights has been provided.\n",
        "#     :param trainable: Whether the layers are trainable.\n",
        "#     :return: Keras model.\n",
        "#     \"\"\"\n",
        "#     if not isinstance(token_num, list):\n",
        "#         token_num = [token_num, token_num]\n",
        "#     encoder_token_num, decoder_token_num = token_num\n",
        "\n",
        "#     if not isinstance(embed_weights, list):\n",
        "#         embed_weights = [embed_weights, embed_weights]\n",
        "#     encoder_embed_weights, decoder_embed_weights = embed_weights\n",
        "#     if encoder_embed_weights is not None:\n",
        "#         encoder_embed_weights = [encoder_embed_weights]\n",
        "#     if decoder_embed_weights is not None:\n",
        "#         decoder_embed_weights = [decoder_embed_weights]\n",
        "\n",
        "#     if not isinstance(embed_trainable, list):\n",
        "#         embed_trainable = [embed_trainable, embed_trainable]\n",
        "#     encoder_embed_trainable, decoder_embed_trainable = embed_trainable\n",
        "#     if encoder_embed_trainable is None:\n",
        "#         encoder_embed_trainable = encoder_embed_weights is None\n",
        "#     if decoder_embed_trainable is None:\n",
        "#         decoder_embed_trainable = decoder_embed_weights is None\n",
        "\n",
        "#     if use_same_embed:\n",
        "#         encoder_embed_layer = decoder_embed_layer = EmbeddingRet(\n",
        "#             input_dim=encoder_token_num,\n",
        "#             output_dim=embed_dim,\n",
        "#             mask_zero=True,\n",
        "#             weights=encoder_embed_weights,\n",
        "#             trainable=encoder_embed_trainable,\n",
        "#             name='Token-Embedding',\n",
        "#         )\n",
        "#     else:\n",
        "#         encoder_embed_layer = EmbeddingRet(\n",
        "#             input_dim=encoder_token_num,\n",
        "#             output_dim=embed_dim,\n",
        "#             mask_zero=True,\n",
        "#             weights=encoder_embed_weights,\n",
        "#             trainable=encoder_embed_trainable,\n",
        "#             name='Encoder-Token-Embedding',\n",
        "#         )\n",
        "#         decoder_embed_layer = EmbeddingRet(\n",
        "#             input_dim=decoder_token_num,\n",
        "#             output_dim=embed_dim,\n",
        "#             mask_zero=True,\n",
        "#             weights=decoder_embed_weights,\n",
        "#             trainable=decoder_embed_trainable,\n",
        "#             name='Decoder-Token-Embedding',\n",
        "#         )\n",
        "#     encoder_input = Input(shape=(None,), name='Encoder-Input')\n",
        "#     encoder_embed = TrigPosEmbedding(\n",
        "#         mode=TrigPosEmbedding.MODE_ADD,\n",
        "#         name='Encoder-Embedding',\n",
        "#     )(encoder_embed_layer(encoder_input)[0])\n",
        "#     encoded_layer = get_encoders(\n",
        "#         encoder_num=encoder_num,\n",
        "#         input_layer=encoder_embed,\n",
        "#         head_num=head_num,\n",
        "#         hidden_dim=hidden_dim,\n",
        "#         attention_activation=attention_activation,\n",
        "#         feed_forward_activation=feed_forward_activation,\n",
        "#         dropout_rate=dropout_rate,\n",
        "#         trainable=trainable,\n",
        "#     )\n",
        "#     decoder_input = Input(shape=(None,), name='Decoder-Input')\n",
        "#     decoder_embed, decoder_embed_weights = decoder_embed_layer(decoder_input)\n",
        "#     decoder_embed = TrigPosEmbedding(\n",
        "#         mode=TrigPosEmbedding.MODE_ADD,\n",
        "#         name='Decoder-Embedding',\n",
        "#     )(decoder_embed)\n",
        "#     decoded_layer = get_decoders(\n",
        "#         decoder_num=decoder_num,\n",
        "#         input_layer=decoder_embed,\n",
        "#         encoded_layer=encoded_layer,\n",
        "#         head_num=head_num,\n",
        "#         hidden_dim=hidden_dim,\n",
        "#         attention_activation=attention_activation,\n",
        "#         feed_forward_activation=feed_forward_activation,\n",
        "#         dropout_rate=dropout_rate,\n",
        "#         trainable=trainable,\n",
        "#     )\n",
        "#     output_layer = EmbeddingSim(\n",
        "#         trainable=trainable,\n",
        "#         name='Decoder-Output',\n",
        "#     )([decoded_layer, decoder_embed_weights])\n",
        "#     return keras.models.Model(inputs=[encoder_input, decoder_input], outputs=output_layer)\n",
        "\n",
        "def _get_max_suffix_repeat_times(tokens, max_len):\n",
        "    detect_len = min(max_len, len(tokens))\n",
        "    next = [-1] * detect_len\n",
        "    k = -1\n",
        "    for i in range(1, detect_len):\n",
        "        while k >= 0 and tokens[len(tokens) - i - 1] != tokens[len(tokens) - k - 2]:\n",
        "            k = next[k]\n",
        "        if tokens[len(tokens) - i - 1] == tokens[len(tokens) - k - 2]:\n",
        "            k += 1\n",
        "        next[i] = k\n",
        "    max_repeat = 1\n",
        "    for i in range(2, detect_len):\n",
        "        if next[i] >= 0 and (i + 1) % (i - next[i]) == 0:\n",
        "            max_repeat = max(max_repeat, (i + 1) // (i - next[i]))\n",
        "    return max_repeat\n",
        "\n",
        "def decode(model,\n",
        "      tokens,\n",
        "      start_token,\n",
        "      end_token,\n",
        "      pad_token,\n",
        "      top_k=1,\n",
        "      temperature=1.0,\n",
        "      max_len=10000,\n",
        "      max_repeat=10,\n",
        "      max_repeat_block=10):\n",
        "    \"\"\"Decode with the given model and input tokens.\n",
        "    :param model: The trained model.\n",
        "    :param tokens: The input tokens of encoder.\n",
        "    :param start_token: The token that represents the start of a sentence.\n",
        "    :param end_token: The token that represents the end of a sentence.\n",
        "    :param pad_token: The token that represents padding.\n",
        "    :param top_k: Choose the last token from top K.\n",
        "    :param temperature: Randomness in boltzmann distribution.\n",
        "    :param max_len: Maximum length of decoded list.\n",
        "    :param max_repeat: Maximum number of repeating blocks.\n",
        "    :param max_repeat_block: Maximum length of the repeating block.\n",
        "    :return: Decoded tokens.\n",
        "    \"\"\"\n",
        "    is_single = not isinstance(tokens[0], list)\n",
        "    if is_single:\n",
        "        tokens = [tokens]\n",
        "    batch_size = len(tokens)\n",
        "    decoder_inputs = [[start_token] for _ in range(batch_size)]\n",
        "    outputs = [None for _ in range(batch_size)]\n",
        "    output_len = 1\n",
        "    while len(list(filter(lambda x: x is None, outputs))) > 0:\n",
        "        output_len += 1\n",
        "        batch_inputs, batch_outputs = [], []\n",
        "        max_input_len = 0\n",
        "        index_map = {}\n",
        "        for i in range(batch_size):\n",
        "            if outputs[i] is None:\n",
        "                index_map[len(batch_inputs)] = i\n",
        "                batch_inputs.append(tokens[i][:])\n",
        "                batch_outputs.append(decoder_inputs[i])\n",
        "                max_input_len = max(max_input_len, len(tokens[i]))\n",
        "        for i in range(len(batch_inputs)):\n",
        "            batch_inputs[i] += [pad_token] * (max_input_len - len(batch_inputs[i]))\n",
        "        predicts = model.predict([np.array(batch_inputs), np.array(batch_outputs)])\n",
        "        for i in range(len(predicts)):\n",
        "            if top_k == 1:\n",
        "                last_token = predicts[i][-1].argmax(axis=-1)\n",
        "            else:\n",
        "                probs = [(prob, j) for j, prob in enumerate(predicts[i][-1])]\n",
        "                probs.sort(reverse=True)\n",
        "                probs = probs[:top_k]\n",
        "                indices, probs = list(map(lambda x: x[1], probs)), list(map(lambda x: x[0], probs))\n",
        "                probs = np.array(probs) / temperature\n",
        "                probs = probs - np.max(probs)\n",
        "                probs = np.exp(probs)\n",
        "                probs = probs / np.sum(probs)\n",
        "                last_token = np.random.choice(indices, p=probs)\n",
        "            decoder_inputs[index_map[i]].append(last_token)\n",
        "            if last_token == end_token or\\\n",
        "                    (max_len is not None and output_len >= max_len) or\\\n",
        "                    _get_max_suffix_repeat_times(decoder_inputs[index_map[i]],\n",
        "                                                 max_repeat * max_repeat_block) >= max_repeat:\n",
        "                outputs[index_map[i]] = decoder_inputs[index_map[i]]\n",
        "    if is_single:\n",
        "        outputs = outputs[0]\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFs9AEMBTOf"
      },
      "source": [
        "# 2. Self-defined Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1xPvz41BV6t"
      },
      "outputs": [],
      "source": [
        "def get_centers(y_true,y_pred,centers):\n",
        "        output_list = []\n",
        "        for i in range(AU_count):\n",
        "            labels = tf.reshape(y_true[:,i],[-1])\n",
        "            labels = tf.cast(labels,tf.float32)\n",
        "            # masked_features = centers[i,...]+y_pred[:,i,:]*labels[:,tf.newaxis]\n",
        "            masked_features = centers[i, ...] + y_pred[:, i, :] * tf.expand_dims(labels, axis=-1)\n",
        "            moving_average = tf.math.reduce_mean(masked_features,axis=0)\n",
        "            output_list.append(moving_average)\n",
        "        centers = tf.stack(output_list)\n",
        "        return centers\n",
        "\n",
        "def get_center_loss(alpha,y_true,y_pred,centers):\n",
        "    loss=0\n",
        "    for i in range(AU_count):\n",
        "        labels = tf.reshape(y_true[:,i],[-1])\n",
        "        labels = tf.cast(labels,tf.float32)\n",
        "        # diff = alpha[i]*(y_pred[:,i,:]-centers[i,...])*labels[:,tf.newaxis]\n",
        "        diff = alpha[i] * (y_pred[:, i, :] - centers[i, ...]) * tf.expand_dims(labels, axis=-1)\n",
        "        loss += tf.reduce_mean(tf.square(diff))\n",
        "    return loss\n",
        "\n",
        "def get_divergence_loss(alpha,y_true,y_pred,centers):\n",
        "    loss=0\n",
        "    for i in range(AU_count):\n",
        "        labels = tf.reshape(1-y_true[:,i],[-1])\n",
        "        labels = tf.cast(labels,tf.float32)\n",
        "        # diff = alpha[i]*(y_pred[:,i,:]-centers[i,...])*labels[:,tf.newaxis]\n",
        "        diff = alpha[i] * (y_pred[:, i, :] - centers[i, ...]) * tf.expand_dims(labels, axis=-1)\n",
        "        loss += tf.reduce_mean(tf.square(diff))\n",
        "    return loss\n",
        "\n",
        "# def get_full_center_loss(alpha, feature_dim,ind):\n",
        "#     # Build a graph\n",
        "#     graph = tf.Graph()\n",
        "#     with graph.as_default():\n",
        "#         centers = tf.compat.v1.get_variable('centers_{}'.format(ind), shape=[AU_count,256],\n",
        "#                             initializer=tf.compat.v1.constant_initializer(0),\n",
        "#                             dtype=tf.float32)     # Create a variable tensor\n",
        "\n",
        "#     # Create a session, and run the graph\n",
        "#     with tf.compat.v1.Session(graph=graph) as session:\n",
        "#         tf.compat.v1.global_variables_initializer().run()  # Initialize values of all variable tensors\n",
        "#         output_a = session.run(centers)            # Return the value of the variable tensor\n",
        "\n",
        "#     centers = output_a\n",
        "#     # print(centers)\n",
        "#     def center_loss(y_true, y_pred):\n",
        "# #         a = np.zeros([AU_count, feature_dim])\n",
        "#         c = tf.constant(centers)\n",
        "#         c = get_centers(y_true,y_pred,c)\n",
        "# #         centers = c\n",
        "# #         centers.assign(c)\n",
        "#         num_loss = get_center_loss(alpha,y_true,y_pred,c)\n",
        "#         den_loss = get_divergence_loss(alpha,y_true,y_pred,c)\n",
        "#         # print(\"full num_loss return shape: \", den_loss.shape)\n",
        "#         # print(\"full den_loss return shape: \", num_loss.shape)\n",
        "#         # print(\"full center loss return shape: \", (num_loss/den_loss).shape)\n",
        "#         return num_loss/den_loss\n",
        "\n",
        "#     return center_loss\n",
        "\n",
        "# rewrite the get_full_center_loss in tensorflow 2.15 style\n",
        "def get_full_center_loss(alpha, feature_dim, ind):\n",
        "  centers = tf.Variable(tf.zeros([AU_count, 256]), name='centers_{}'.format(ind), dtype=tf.float32)\n",
        "  def center_loss(y_true, y_pred):\n",
        "      c = get_centers(y_true, y_pred, centers)\n",
        "      num_loss = get_center_loss(alpha, y_true, y_pred, c)\n",
        "      den_loss = get_divergence_loss(alpha, y_true, y_pred, c)\n",
        "      return num_loss / den_loss\n",
        "  return center_loss\n",
        "\n",
        "# the weighted_bce loss is depricated \n",
        "def weighted_bce(y_true, y_pred,weights):\n",
        "    # weights = ((y_true) * 59.) + 1.\n",
        "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred,from_logits=False)\n",
        "    weighted_bce = tf.math.reduce_mean(bce * weights)\n",
        "    return weighted_bce\n",
        "\n",
        "def macro_soft_f1(weights):\n",
        "    def loss(y, y_hat):\n",
        "        \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
        "        Use probability values instead of binary predictions.\n",
        "        Args:\n",
        "            y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
        "            y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        Returns:\n",
        "            cost (scalar Tensor): value of the cost function for the batch\n",
        "        \"\"\"\n",
        "        # print(weights)\n",
        "        # ensure data type\n",
        "        y = tf.cast(y, tf.float32)\n",
        "        y_hat = tf.cast(y_hat, tf.float32)\n",
        "        # calculate component for soft f1\n",
        "        tp = tf.math.reduce_sum(y_hat * y, axis=0)\n",
        "        fp = tf.math.reduce_sum(y_hat * (1 - y), axis=0)\n",
        "        fn = tf.math.reduce_sum((1 - y_hat) * y, axis=0)\n",
        "        tn = tf.math.reduce_sum((1 - y_hat) * (1-y), axis=0)\n",
        "        # soft f1 is calculated by F1 = (tp/(tp+0.25fn+0.75fp))\n",
        "        soft_f1 = (tp+ 1e-16) / (tp + 0.25*fn + 0.75*fp + 1e-16)\n",
        "        # the lower the soft f1 the higher the cost\n",
        "        cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
        "        macro_cost = tf.math.reduce_mean(cost*weights)+weighted_bce(y,y_hat,weights) # +average on all labels\n",
        "        return macro_cost\n",
        "    return loss\n",
        "\n",
        "# for attention map loss calculation\n",
        "def huber_loss(y_true, y_pred, clip_delta=0.1):\n",
        "    error = y_true - y_pred\n",
        "    cond  = tf.math.abs(error) < clip_delta\n",
        "    squared_loss = 0.5 * tf.math.square(error)\n",
        "    linear_loss  = clip_delta * (tf.math.abs(error) - 0.5 * clip_delta)\n",
        "    return tf.where(cond, squared_loss, linear_loss)\n",
        "\n",
        "def macro_f1(y, y_hat, thresh=0.5):\n",
        "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
        "    Args:\n",
        "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        thresh: probability value above which we predict positive\n",
        "    Returns:\n",
        "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
        "    \"\"\"\n",
        "    y_pred = tf.cast(tf.math.greater(y_hat, thresh), tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = (2*tp+1e-16) / (2*tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.math.reduce_mean(f1)#+tf.keras.losses.binary_crossentropy(y,y_hat)\n",
        "    return macro_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t3Jdt6FxjvG"
      },
      "source": [
        "# 3. Load Pretrained Model\n",
        "+ The pretrained model is trained and saved using tf==1.15, but it is still usable after changing the code to tf==2.15 style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YVa3gPAy3vT"
      },
      "outputs": [],
      "source": [
        "# use InceptionV3 as the feature extracter\n",
        "base_model0 = InceptionV3(weights=\"imagenet\",include_top=False, input_shape= (224,224,3))\n",
        "base_model = Model(inputs=base_model0.input,outputs = base_model0.get_layer('activation_74').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozvc37ljFM9g"
      },
      "outputs": [],
      "source": [
        "AU_count=12\n",
        "data_path = './DISFA_fold/'\n",
        "ind1 = [0, 1, 2, 3, 4, 6, 8, 10, 11, 12, 15, 16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl2_3WGZFRIP"
      },
      "outputs": [],
      "source": [
        "def batch_generator(x):\n",
        "    attsize=12\n",
        "    i=0\n",
        "    ind = ind1\n",
        "    while True:\n",
        "      sample_idx = 0\n",
        "      batch = 0\n",
        "      print('entering ... ',len(x))\n",
        "      while sample_idx  < len(x):\n",
        "        l = np.load(data_path+x[sample_idx]) # load an npz file with x_train, y_train, x_train_att\n",
        "        x_train1 = l['x_train1']\n",
        "        x_train1 = np.concatenate((x_train1,x_train1,x_train1),axis=-1) # (224,224,1) -> (224, 224, 3)\n",
        "        x_train_att = l['x_train_att']\n",
        "        x_train_att = np.resize(x_train_att,(64,attsize,attsize,18))\n",
        "        y_train1 = l['y_train']\n",
        "        x_train1_att = x_train_att[...,ind]/255.\n",
        "        y_train=y_train1[:,ind]\n",
        "        y_train1 = np.expand_dims(y_train,axis=-2)\n",
        "        y_train2 = y_train\n",
        "        sample_idx += 1\n",
        "        batch+=1\n",
        "        # print(\"att_outputs: \", y_train.shape)\n",
        "        # print(\"per_output: \", y_train.shape)\n",
        "        # print(\"att_loss:\", x_train1_att.shape)\n",
        "        # print(\"feat_outputs: \", y_train.shape)\n",
        "        yield(x_train1, {\"att_outputs\":y_train,\"per_outputs_{}\".format(AU_count): y_train, \"att_loss\":x_train1_att,\"feat_outputs_{}\".format(AU_count):y_train})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agzs8kGSE3I-"
      },
      "outputs": [],
      "source": [
        "# need to create image list file\n",
        "img_list = [] # store the name of each image(\"SN001_frame_28.jpg\")\n",
        "img_path_list = [] # store each image's path\n",
        "IMAGE_PATH = './dataset/frames'\n",
        "for subject in os.listdir(IMAGE_PATH):\n",
        "  subject_path = os.path.join(IMAGE_PATH, subject)\n",
        "  for frame in os.listdir(subject_path):\n",
        "    img_list.append(\"{}_{}\".format(subject, frame))\n",
        "    curr_path = os.path.join(subject_path, frame)\n",
        "    img_path_list.append(curr_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fodLE5IqE5Ot"
      },
      "outputs": [],
      "source": [
        "fold1 = ['SN002','SN010','SN001','SN026','SN027','SN030','SN032','SN009','SN016']\n",
        "fold2 = ['SN006','SN011','SN012','SN013','SN018','SN021','SN024','SN028','SN031']\n",
        "fold3 = ['SN003','SN004','SN005','SN007','SN008','SN017','SN023','SN025','SN029']\n",
        "\n",
        "Total_att_acc =[];Total_perc_acc=[];Total_att_f1 =[];Total_perc_f1=[]\n",
        "index_list = [] # store the index = 4845 * (subject_idx-1) + frame - 1\n",
        "index_im_list = [] # store the img_path\n",
        "\n",
        "images = img_list\n",
        "\n",
        "for _ in range(3):\n",
        "    index_list.append([])\n",
        "    index_im_list.append([])\n",
        "for im in range(len(images)):\n",
        "    subject = images[im].split('_')[0]\n",
        "    subject_idx = int(subject[2:])\n",
        "    img_idx = 4845 * (subject_idx-1) + int(images[im].split('_')[2][:-4]) - 1\n",
        "    if subject in fold1:\n",
        "        index_list[0].append(img_idx);index_im_list[0].append(img_path_list[im])\n",
        "    elif subject in fold2:\n",
        "        index_list[1].append(img_idx);index_im_list[1].append(img_path_list[im])\n",
        "    elif subject in fold3:\n",
        "        index_list[2].append(img_idx);index_im_list[2].append(img_path_list[im])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3jpl0yxE8_v",
        "outputId": "5fd29807-eb65-4e18-e96e-4018527f08d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1122/1122 [13:44<00:00,  1.36it/s]\n"
          ]
        }
      ],
      "source": [
        "# use fold1 and fold2 as the training set, and keep fold0 as the test set \n",
        "dataset = 'DISFA'\n",
        "\n",
        "ind = 0\n",
        "# use one fold as validation set and the resting two folds as the training set\n",
        "x_test = index_im_list[ind]\n",
        "new = list(range(3))\n",
        "new.remove(ind)\n",
        "\n",
        "# load the processed data\n",
        "batches_test = [f for f in os.listdir(data_path) if f.startswith(dataset+'_fold'+str(ind))]\n",
        "\n",
        "batches_train = [f for f in os.listdir(data_path) if f.startswith(dataset+'_fold'+str(new[0]))]\n",
        "\n",
        "batches_train += [f for f in os.listdir(data_path) if f.startswith(dataset+'_fold'+str(new[1]))]\n",
        "\n",
        "y_train = np.zeros((len(batches_train)*64,AU_count ), dtype='float32')\n",
        "row=0\n",
        "for batch_iter in tqdm(batches_train):\n",
        "    t_t=np.load(data_path+batch_iter)['y_train'][:,ind1] # extract the au exisit in DISFA dataset\n",
        "    y_train[row:row+t_t.shape[0],...]=t_t\n",
        "    row+=t_t.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKIqoZoZFEjr"
      },
      "outputs": [],
      "source": [
        "# Initialize alpha and weights(here weights are used for weighted loss generation)\n",
        "tp = np.sum(y_train,axis=0)\n",
        "fp = np.sum((1-y_train),axis=0)\n",
        "Pni = (tp+1e-6)/(tp+fp+1e-6)\n",
        "alpha = 1/(AU_count*Pni)\n",
        "Psi = np.power(alpha,0.5)*Pni\n",
        "weights = np.sum(Psi)/Psi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIh0Q2w1ylm-"
      },
      "outputs": [],
      "source": [
        "def baseline_model_best(AU_count,weights,ind):\n",
        "  fc_dim = 256\n",
        "  inputs = Input(shape=(224,224,3))\n",
        "\n",
        "  #block 1\n",
        "  g = base_model(inputs)\n",
        "\n",
        "  gh = Conv2D(64, (3,3), padding='same', kernel_initializer='glorot_normal')(g)\n",
        "  gh1 = Conv2D(AU_count, (1,1), padding='same', kernel_initializer='glorot_normal')(gh)\n",
        "  gh2 = Conv2D(AU_count, (1,1), padding='same', activation='sigmoid',name = \"att_loss\", kernel_initializer='glorot_normal')(gh1)\n",
        "  gh1 = Conv2D(AU_count, (1,1), padding='same', activation='linear', kernel_initializer='glorot_normal')(gh1)\n",
        "  gap = GlobalAveragePooling2D()(gh1)\n",
        "  att_output = Activation('sigmoid',name=\"att_outputs\")(gap)\n",
        "  attention = gh2\n",
        "  reshape_embed = Reshape([12*12,AU_count])(attention)\n",
        "  reshape_embed = Permute((2,1))(reshape_embed)\n",
        "  print(\"in model attention shape: \", attention.shape)\n",
        "\n",
        "  # AU attention layers\n",
        "  for i in range(AU_count):\n",
        "\n",
        "      # layer1 = Lambda(lambda x: tf.expand_dims(attention[...,i],axis=-1))(attention)\n",
        "      layer1 = tf.expand_dims(attention[..., i], axis=-1)\n",
        "\n",
        "      out = Multiply()([layer1,g])\n",
        "      g = Add()([out,g])\n",
        "      mt = Conv2D(64, (1,1), padding='same', kernel_initializer='glorot_normal')(g)\n",
        "      mt = MaxPooling2D(pool_size=7, strides=(1,1),padding = 'same')(mt)\n",
        "      mt = BatchNormalization()(mt)\n",
        "      mt = Activation('relu')(mt)\n",
        "      perception = Flatten()(mt)\n",
        "\n",
        "      inter = Dense(fc_dim, activation='relu', kernel_initializer='glorot_normal')(perception)\n",
        "      # tin = Lambda(lambda x: tf.expand_dims(x,axis=1))(inter)\n",
        "      tin = tf.expand_dims(inter, axis=1)\n",
        "      if i==0:\n",
        "          feat_outputs = tin\n",
        "      else:\n",
        "          feat_outputs = Concatenate(axis = 1, name = 'feat_outputs_{}'.format(i+1))([feat_outputs,tin])\n",
        "\n",
        "  feat_outputs_P  = PositionEmbedding(\n",
        "      input_shape=(None,),\n",
        "      input_dim = AU_count,\n",
        "      output_dim = fc_dim,\n",
        "      mask_zero=0,\n",
        "      mode=PositionEmbedding.MODE_ADD,)(feat_outputs)\n",
        "  feat_outputs_P = get_encoders(name = '1',encoder_num=3,\n",
        "                  input_layer=feat_outputs_P,\n",
        "                  head_num=8,hidden_dim=fc_dim,\n",
        "                  dropout_rate=0.1,)\n",
        "\n",
        "  feat_outputs_P = Flatten()(feat_outputs_P)\n",
        "  inter = Dense(fc_dim, activation='relu', kernel_initializer='glorot_normal')(feat_outputs_P)\n",
        "  final = Dense(AU_count,\n",
        "          activation='sigmoid',\n",
        "          name = 'per_outputs_{}'.format(AU_count),\n",
        "          kernel_initializer='glorot_normal')(inter)\n",
        "  model = Model(inputs=inputs, outputs=[att_output,final,attention,feat_outputs])\n",
        "  # model.summary()\n",
        "\n",
        "  # losses = {\n",
        "  #     \"att_outputs\": macro_soft_f1(weights),\n",
        "  #     \"per_outputs_{}\".format(i+1): macro_soft_f1(weights),\n",
        "  #     \"att_loss\": huber_loss,\n",
        "  #     'feat_outputs_{}'.format(i+1):get_full_center_loss(weights,fc_dim,ind)\n",
        "  #     }\n",
        "\n",
        "  losses = {\n",
        "      \"att_outputs\": \"binary_crossentropy\",\n",
        "      \"per_outputs_{}\".format(AU_count): \"binary_crossentropy\",\n",
        "      \"att_loss\": huber_loss,\n",
        "      'feat_outputs_{}'.format(AU_count):get_full_center_loss(weights,fc_dim,ind)\n",
        "      }\n",
        "\n",
        "  lossWeights = {\"att_outputs\": 0.25,\n",
        "          \"per_outputs_{}\".format(AU_count): 0.25,\n",
        "          \"att_loss\":0.25,\n",
        "          'feat_outputs_{}'.format(AU_count):0.25}\n",
        "  \n",
        "  # initialize the optimizer and compile the model\n",
        "  print(\"[INFO] compiling model...\")\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "  model.compile(optimizer=opt,\n",
        "          loss=losses,\n",
        "          loss_weights=lossWeights,\n",
        "          metrics={'att_outputs':macro_f1,\n",
        "          \"per_outputs_{}\".format(AU_count):macro_f1,\n",
        "          \"att_loss\":huber_loss})\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfauSYqsTNaH",
        "outputId": "3b856e0b-979e-4829-d511-bc16b7966831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in model attention shape:  (None, 12, 12, 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-7f6a865e03a2>:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  trainer = model.fit_generator(batch_generator(batches_train),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entering ...  1122\n",
            "1120/1122 [============================>.] - ETA: 1s - loss: 0.3307 - att_outputs_loss: 0.9209 - per_outputs_12_loss: 0.3678 - att_loss_loss: 0.0343 - feat_outputs_12_loss: 2.9083e-10 - att_outputs_macro_f1: 0.4179 - per_outputs_12_macro_f1: 0.7314 - att_loss_huber_loss: 0.0343entering ...  1122\n",
            "1122/1122 [==============================] - ETA: 0s - loss: 0.3282 - att_outputs_loss: 0.9187 - per_outputs_12_loss: 0.3599 - att_loss_loss: 0.0343 - feat_outputs_12_loss: 2.9109e-10 - att_outputs_macro_f1: 0.4184 - per_outputs_12_macro_f1: 0.7316 - att_loss_huber_loss: 0.0343entering ...  378\n",
            "entering ...  378\n",
            "1122/1122 [==============================] - 1085s 907ms/step - loss: 0.3282 - att_outputs_loss: 0.9187 - per_outputs_12_loss: 0.3599 - att_loss_loss: 0.0343 - feat_outputs_12_loss: 2.9109e-10 - att_outputs_macro_f1: 0.4184 - per_outputs_12_macro_f1: 0.7316 - att_loss_huber_loss: 0.0343 - val_loss: 1.0279 - val_att_outputs_loss: 0.6831 - val_per_outputs_12_loss: 3.0810 - val_att_loss_loss: 0.0338 - val_feat_outputs_12_loss: 0.3139 - val_att_outputs_macro_f1: 0.5313 - val_per_outputs_12_macro_f1: 0.6831 - val_att_loss_huber_loss: 0.0338 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "model = baseline_model_best(AU_count,weights*0.1,ind)\n",
        "if ind==-1: # here we don't train from scratch thus set it to -1\n",
        "    model.save_weights('initial.h5')\n",
        "else: # use model pretrained on BP4D dataset and finetune it on DISFA dataset\n",
        "    model.load_weights('Pretrianed_Transformer_FAU_fold0.h5')\n",
        "# initialize the optimizer and compile the model\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_per_outputs_12_macro_f1',\n",
        "                              mode='max',factor=0.2,\n",
        "                              patience=3, min_lr=0.0000001)\n",
        "mcp_save = ModelCheckpoint('models/Transformer_FAU_fold{}_newversion.h5'.format(ind),\n",
        "              save_best_only=True, save_weights_only=True,\n",
        "              monitor='val_att_outputs_macro_f1', mode='max')\n",
        "if ind>=0:\n",
        "  # use fit_generator to load data with batch in case the memeroy does not fit\n",
        "  trainer = model.fit_generator(batch_generator(batches_train),\n",
        "            validation_data= batch_generator(batches_test),\n",
        "            epochs = 1,\n",
        "            steps_per_epoch=len(batches_train) ,\n",
        "            validation_steps=len(batches_test),\n",
        "            callbacks=[reduce_lr,mcp_save])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DHHGY2Rfijf"
      },
      "source": [
        "# 4. Model Inference\n",
        "+ Use the finetuned model for test set inference and check its F1 score on each exisiting AU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12-uMLg6oJAY",
        "outputId": "db923850-7b75-4795-8a47-d7aae79bb826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting ./DISFA_fold/DISFA_fold0_10059.npz\n",
            "2/2 [==============================] - 0s 92ms/step\n",
            "(64, 12)\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 64 FN 0 TN 0\n",
            "TP 0 FP 0 FN 0 TN 64\n",
            "TP 0 FP 7 FN 0 TN 57\n",
            "TP 0 FP 59 FN 0 TN 5\n",
            " f1 score .... [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "# predict one batch of testing data\n",
        "y_pred_acc = []\n",
        "y_pred_f1 = np.array([])\n",
        "y_true_ex = []\n",
        "\n",
        "data_test_fold0 = './DISFA_fold/DISFA_fold0_10059.npz'\n",
        "# model.load_weights('Transformer_FAU_fold0.h5')\n",
        "print('Predicting '+ data_test_fold0)\n",
        "x = np.load(data_test_fold0)\n",
        "x_train1 = x['x_train1']\n",
        "x_train1 = np.concatenate((x_train1,x_train1,x_train1),axis=-1)\n",
        "y_predict = model.predict(x_train1)\n",
        "y_test = x['y_train']\n",
        "y_test=y_test[:,ind1]\n",
        "\n",
        "y_pred = y_predict[1]\n",
        "t = y_pred[2]\n",
        "print(y_pred.shape)\n",
        "y_pred_acc.append(y_pred)\n",
        "y_true = y_test>0.5\n",
        "\n",
        "y_true_ex.append(y_true)\n",
        "\n",
        "y_pred_acc = np.vstack(y_pred_acc)\n",
        "y_true_ex = np.vstack(y_true_ex)\n",
        "att_f1=[]\n",
        "for l in range(AU_count):\n",
        "    a = np.multiply(y_true_ex[:,l],1)\n",
        "    b = np.multiply(y_pred_acc[:,l]>0.5,1)\n",
        "    TP = sum(np.multiply(np.logical_and(a==1,b==1),1))\n",
        "    FP = sum(np.multiply(np.logical_and(a==0,b==1),1))\n",
        "    FN = sum(np.multiply(np.logical_and(a==1,b==0),1))\n",
        "    TN = sum(np.multiply(np.logical_and(a==0,b==0),1))\n",
        "    Precision = TP/(TP+FP+0.00001)\n",
        "    print('TP',TP,'FP',FP,'FN',FN,'TN',TN)\n",
        "    Recall = TP/(TP+FN+0.00001)\n",
        "    att_f1.append(2*Precision*Recall/(Precision+Recall+0.000001))\n",
        "\n",
        "print(' f1 score ....', att_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPGsBCXy4ypf"
      },
      "outputs": [],
      "source": [
        "# predict the whole test set \n",
        "data_directory = './DISFA_fold/'\n",
        "\n",
        "npz_files = [f for f in os.listdir(data_directory) if f.startswith('DISFA_fold0')]\n",
        "y_pred_acc = []\n",
        "y_pred_f1 = np.array([])\n",
        "y_true_ex = []\n",
        "\n",
        "for file_name in npz_files:\n",
        "    data_test = data_directory + file_name\n",
        "    print('Predicting ' + data_test)\n",
        "\n",
        "    # Load data from .npz file\n",
        "    x = np.load(data_test)\n",
        "    x_train1 = x['x_train1']\n",
        "    x_train1 = np.concatenate((x_train1, x_train1, x_train1), axis=-1)\n",
        "    y_test = x['y_train']\n",
        "    y_test = y_test[:, ind1]\n",
        "\n",
        "    # Predict using the model\n",
        "    y_predict = model.predict(x_train1)\n",
        "    y_pred = y_predict[1]\n",
        "\n",
        "    # Store predictions and ground truth for each file\n",
        "    y_pred_acc.append(y_pred)\n",
        "    y_true_ex.append(y_test)\n",
        "\n",
        "# Concatenate predictions and ground truth arrays\n",
        "y_pred_acc = np.vstack(y_pred_acc)\n",
        "y_true_ex = np.vstack(y_true_ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFkO74yG7JWc",
        "outputId": "0d4a1fd4-bfd3-46cd-cc05-e866d999775a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TP 0 FP 3 FN 0 TN 24189\n",
            "TP 0 FP 0 FN 0 TN 24192\n",
            "TP 0 FP 13 FN 0 TN 19334\n",
            "TP 0 FP 0 FN 0 TN 24192\n",
            "TP 0 FP 8931 FN 0 TN 15261\n",
            "TP 0 FP 202 FN 0 TN 23990\n",
            "TP 4252 FP 2059 FN 592 TN 12444\n",
            "TP 0 FP 0 FN 0 TN 24192\n",
            "TP 0 FP 24192 FN 0 TN 0\n",
            "TP 0 FP 16 FN 0 TN 24176\n",
            "TP 0 FP 5469 FN 0 TN 13878\n",
            "TP 3541 FP 6223 FN 1303 TN 8280\n",
            " f1 score .... [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7623482298269417, 0.0, 0.0, 0.0, 0.0, 0.4848024038090206]\n"
          ]
        }
      ],
      "source": [
        "att_f1 = []\n",
        "for l in range(AU_count):\n",
        "    a = np.multiply(y_true_ex[:, l], 1)\n",
        "    b = np.multiply(y_pred_acc[:, l] > 0.5, 1)\n",
        "    TP = sum(np.multiply(np.logical_and(a == 1, b == 1), 1))\n",
        "    FP = sum(np.multiply(np.logical_and(a == 0, b == 1), 1))\n",
        "    FN = sum(np.multiply(np.logical_and(a == 1, b == 0), 1))\n",
        "    TN = sum(np.multiply(np.logical_and(a == 0, b == 0), 1))\n",
        "    Precision = TP / (TP + FP + 0.00001)\n",
        "    print('TP',TP,'FP',FP,'FN',FN,'TN',TN)\n",
        "    Recall = TP / (TP + FN + 0.00001)\n",
        "    att_f1.append(2 * Precision * Recall / (Precision + Recall + 0.000001))\n",
        "print(' f1 score ....', att_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7TAZqoAth9L"
      },
      "source": [
        "# 5. Loss Check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lATLEr-DtmIs",
        "outputId": "07ee9ad9-3595-4f28-e58e-fc9c3a218cbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'loss': [0.3282294273376465],\n",
              " 'att_outputs_loss': [0.9186989665031433],\n",
              " 'per_outputs_12_loss': [0.35993966460227966],\n",
              " 'att_loss_loss': [0.03427758440375328],\n",
              " 'feat_outputs_12_loss': [2.910877650030841e-10],\n",
              " 'att_outputs_macro_f1': [0.4184337556362152],\n",
              " 'per_outputs_12_macro_f1': [0.7316012978553772],\n",
              " 'att_loss_huber_loss': [0.03427761793136597],\n",
              " 'val_loss': [1.0279409885406494],\n",
              " 'val_att_outputs_loss': [0.6830723881721497],\n",
              " 'val_per_outputs_12_loss': [3.0810048580169678],\n",
              " 'val_att_loss_loss': [0.033783432096242905],\n",
              " 'val_feat_outputs_12_loss': [0.313903272151947],\n",
              " 'val_att_outputs_macro_f1': [0.5313493013381958],\n",
              " 'val_per_outputs_12_macro_f1': [0.683148980140686],\n",
              " 'val_att_loss_huber_loss': [0.03378342092037201],\n",
              " 'lr': [1e-05]}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.history"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Kk6_qGt6xU5E",
        "9ZMlofTv9xsH",
        "bbFs9AEMBTOf"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
